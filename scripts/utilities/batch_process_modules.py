#!/usr/bin/env python3
"""
æ‰¹é‡å¤„ç†æ¨¡å—1-3ï¼šåŸºäºæœ¬åœ°CSVæ‰§è¡ŒHLè¯†åˆ«ã€ATRè®¡ç®—ã€å¸å¼•åŠ›å¾—åˆ†ã€å…³é”®ä»·ä½å’Œæ‰©å±•ä»·ä½
"""

import os
import sys
import pandas as pd
import numpy as np
import psutil
import time
from datetime import datetime

# æ·»åŠ srcè·¯å¾„
sys.path.append('src')

def monitor_memory():
    """ç›‘æ§å†…å­˜ä½¿ç”¨æƒ…å†µ"""
    memory = psutil.virtual_memory()
    used_gb = memory.used / (1024**3)
    total_gb = memory.total / (1024**3)
    percent = memory.percent
    print(f'å†…å­˜ä½¿ç”¨: {used_gb:.2f}GB / {total_gb:.2f}GB ({percent:.1f}%)')
    return used_gb < 8.0

def process_single_symbol(symbol, csv_file):
    """å¤„ç†å•ä¸ªäº¤æ˜“å¯¹çš„æ‰€æœ‰æ¨¡å—"""
    print(f'\n=== å¤„ç† {symbol} ===')
    print(f'æ–‡ä»¶: {csv_file}')
    
    start_time = time.time()
    
    try:
        # 1. åŠ è½½CSVæ•°æ®
        print('  - åŠ è½½CSVæ•°æ®...')
        df = pd.read_csv(csv_file)
        df['timestamp'] = pd.to_datetime(df['timestamp'])
        print(f'  - æ•°æ®é‡: {len(df)} æ¡è®°å½•')
        print(f'  - æ—¶é—´èŒƒå›´: {df["timestamp"].min()} åˆ° {df["timestamp"].max()}')
        
        # æ£€æŸ¥æ˜¯å¦å·²æœ‰å¯¹æ•°ä»·æ ¼åˆ—
        if 'log_high' not in df.columns:
            print('  - è­¦å‘Š: æœªæ‰¾åˆ°å¯¹æ•°ä»·æ ¼åˆ—ï¼Œè·³è¿‡æ­¤æ–‡ä»¶')
            return False, 0, 0.0
        
        # 2. æ¨¡å—1: HLè¯†åˆ«ä¸å»é‡
        print('  - æ‰§è¡Œæ¨¡å—1: HLè¯†åˆ«ä¸å»é‡...')
        from peak_valley import identify_high_low_points, deduplicate_peaks_valleys
        
        # HLè¯†åˆ«
        hl_df = identify_high_low_points(df, g=3)
        print(f'    - è¯†åˆ«åˆ° {hl_df["is_high"].sum()} ä¸ªé«˜ç‚¹, {hl_df["is_low"].sum()} ä¸ªä½ç‚¹')
        
        # HLå»é‡
        dedup_df = deduplicate_peaks_valleys(hl_df)
        print(f'    - å»é‡å: {dedup_df["is_high"].sum()} ä¸ªé«˜ç‚¹, {dedup_df["is_low"].sum()} ä¸ªä½ç‚¹')
        
        # 3. æ¨¡å—2: ATRè®¡ç®—
        print('  - æ‰§è¡Œæ¨¡å—2: ATRè®¡ç®—...')
        from atr_calculator import calculate_atr
        atr_df = calculate_atr(dedup_df, period=14)
        print(f'    - ATRè®¡ç®—å®Œæˆï¼Œå¹³å‡ATR: {atr_df["atr"].mean():.6f}')
        
        # 4. æ¨¡å—3: å¸å¼•åŠ›å¾—åˆ†è®¡ç®—
        print('  - æ‰§è¡Œæ¨¡å—3: å¸å¼•åŠ›å¾—åˆ†è®¡ç®—...')
        from attraction_score import calculate_attraction_score
        score_df = calculate_attraction_score(atr_df, w=120, band_width=0.1)
        print(f'    - å¸å¼•åŠ›å¾—åˆ†è®¡ç®—å®Œæˆ')
        
        # 5. å…³é”®ä»·ä½è¯†åˆ«
        print('  - æ‰§è¡Œå…³é”®ä»·ä½è¯†åˆ«...')
        from key_levels import filter_key_levels
        key_levels_df = filter_key_levels(score_df, threshold=0.1)
        
        if len(key_levels_df) > 0 and 'key_1' in key_levels_df.columns:
            print(f'    - è¯†åˆ«åˆ° {len(key_levels_df)} ä¸ªå…³é”®ä»·ä½')
            if not key_levels_df['key_1'].isna().all():
                print(f'    - å…³é”®ä»·ä½èŒƒå›´: {key_levels_df["key_1"].min():.6f} åˆ° {key_levels_df["key_1"].max():.6f}')
            else:
                print('    - å…³é”®ä»·ä½æ•°æ®ä¸ºç©º')
        else:
            print('    - æœªè¯†åˆ«åˆ°å…³é”®ä»·ä½')
        
        # 6. æ‰©å±•ä»·ä½è®¡ç®—
        if len(key_levels_df) > 0 and 'key_1' in key_levels_df.columns and not key_levels_df['key_1'].isna().all():
            print('  - æ‰§è¡Œæ‰©å±•ä»·ä½è®¡ç®—...')
            from extended_levels import calculate_extended_levels
            extended_df = calculate_extended_levels(key_levels_df)
            print(f'    - æ‰©å±•ä»·ä½è®¡ç®—å®Œæˆï¼Œç”Ÿæˆ {len(extended_df)} ä¸ªæ‰©å±•ä»·ä½')
        else:
            print('  - è·³è¿‡æ‰©å±•ä»·ä½è®¡ç®—ï¼ˆæ— å…³é”®ä»·ä½ï¼‰')
            extended_df = key_levels_df
        
        # 7. ä¿å­˜ç»“æœ
        output_file = csv_file.replace('.csv', '_processed.csv')
        extended_df.to_csv(output_file, index=False)
        print(f'  - ç»“æœå·²ä¿å­˜åˆ°: {output_file}')
        
        end_time = time.time()
        duration = end_time - start_time
        
        print(f'âœ… {symbol} å¤„ç†å®Œæˆ:')
        print(f'  - è€—æ—¶: {duration:.2f} ç§’')
        print(f'  - è¾“å‡ºæ–‡ä»¶: {output_file}')
        
        return True, len(extended_df), duration
        
    except Exception as e:
        end_time = time.time()
        duration = end_time - start_time
        print(f'âŒ {symbol} å¤„ç†å¤±è´¥: {e}')
        print(f'  - è€—æ—¶: {duration:.2f} ç§’')
        return False, 0, duration

def main():
    print('=== æ‰¹é‡å¤„ç†æ¨¡å—1-3 ===')
    print(f'å¼€å§‹æ—¶é—´: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}')
    print(f'åˆå§‹å†…å­˜çŠ¶æ€:')
    monitor_memory()
    
    # è·å–æ‰€æœ‰CSVæ–‡ä»¶
    data_dir = 'data'
    csv_files = [f for f in os.listdir(data_dir) if f.endswith('_5m.csv')]
    csv_files.sort()
    
    print(f'\nå‘ç° {len(csv_files)} ä¸ªCSVæ–‡ä»¶:')
    for i, file in enumerate(csv_files):
        print(f'  {i+1}. {file}')
    
    if not csv_files:
        print('âŒ æœªæ‰¾åˆ°CSVæ–‡ä»¶')
        return
    
    # ç»Ÿè®¡å˜é‡
    total_processed = 0
    total_duration = 0
    successful_processes = 0
    failed_processes = 0
    
    # é€ä¸ªå¤„ç†
    for i, csv_file in enumerate(csv_files):
        print(f'\n{"="*60}')
        print(f'è¿›åº¦: {i+1}/{len(csv_files)} - {csv_file}')
        print(f'{"="*60}')
        
        # ç›‘æ§å†…å­˜
        if not monitor_memory():
            print('âš ï¸ å†…å­˜ä½¿ç”¨è¿‡é«˜ï¼Œåœæ­¢å¤„ç†')
            break
        
        # æå–äº¤æ˜“å¯¹åç§°
        symbol = csv_file.replace('_5m.csv', '').replace('_', '/')
        
        # å¤„ç†å•ä¸ªäº¤æ˜“å¯¹
        success, records, duration = process_single_symbol(symbol, os.path.join(data_dir, csv_file))
        
        # æ›´æ–°ç»Ÿè®¡
        if success:
            successful_processes += 1
            total_processed += records
        else:
            failed_processes += 1
        
        total_duration += duration
        
        # æ˜¾ç¤ºè¿›åº¦
        print(f'\nğŸ“Š å½“å‰è¿›åº¦ç»Ÿè®¡:')
        print(f'  - å·²å®Œæˆ: {i+1}/{len(csv_files)} ä¸ªäº¤æ˜“å¯¹')
        print(f'  - æˆåŠŸ: {successful_processes} ä¸ª')
        print(f'  - å¤±è´¥: {failed_processes} ä¸ª')
        print(f'  - æ€»å¤„ç†è®°å½•: {total_processed:,} æ¡')
        print(f'  - æ€»è€—æ—¶: {total_duration:.2f} ç§’')
        print(f'  - å¹³å‡è€—æ—¶: {total_duration/(i+1):.2f} ç§’/äº¤æ˜“å¯¹')
        
        # çŸ­æš‚ä¼‘æ¯
        if i < len(csv_files) - 1:
            print(f'  - ç­‰å¾…0.5ç§’åç»§ç»­...')
            time.sleep(0.5)
    
    # æœ€ç»ˆç»Ÿè®¡
    print(f'\n{"="*60}')
    print(f'ğŸ‰ æ‰¹é‡å¤„ç†å®Œæˆ!')
    print(f'{"="*60}')
    print(f'æ€»äº¤æ˜“å¯¹æ•°: {len(csv_files)}')
    print(f'æˆåŠŸå¤„ç†: {successful_processes} ä¸ª')
    print(f'å¤„ç†å¤±è´¥: {failed_processes} ä¸ª')
    print(f'æ€»å¤„ç†è®°å½•: {total_processed:,} æ¡')
    print(f'æ€»è€—æ—¶: {total_duration:.2f} ç§’')
    print(f'å¹³å‡è€—æ—¶: {total_duration/len(csv_files):.2f} ç§’/äº¤æ˜“å¯¹')
    print(f'ç»“æŸæ—¶é—´: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}')
    
    # æ£€æŸ¥è¾“å‡ºæ–‡ä»¶
    print(f'\nğŸ“ è¾“å‡ºæ–‡ä»¶æ£€æŸ¥:')
    processed_files = [f for f in os.listdir(data_dir) if f.endswith('_processed.csv')]
    print(f'å¤„ç†ç»“æœæ–‡ä»¶æ•°é‡: {len(processed_files)}')
    for file in processed_files:
        file_path = os.path.join(data_dir, file)
        file_size = os.path.getsize(file_path) / (1024 * 1024)
        print(f'  - {file}: {file_size:.2f} MB')
    
    print(f'\næœ€ç»ˆå†…å­˜çŠ¶æ€:')
    monitor_memory()

if __name__ == "__main__":
    main()

